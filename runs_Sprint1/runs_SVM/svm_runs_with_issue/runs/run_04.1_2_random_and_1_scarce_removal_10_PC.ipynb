{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all versions 4.x the narrative gets cleaned as before and products are cleaned twice times. The first time half of the three most occuring entries in __Product__ are randomly removed. The second time , the components that almost never occur are removed. This run uses 10 different principle components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialing the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nulls in df_selected: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_selected1 = pd.read_csv(\"../balanced_data/corpus_balanced_cleaned_lemmatized_first_cut_scarce_elimination.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"nulls in df_selected:\", df_selected1[\"Consumer complaint narrative\"].isnull().sum())\n",
    "df_selected = df_selected1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initializing the bag of words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vect (bag of words)\n",
    "count_vect = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    #ngram_range=(1,2), # bigrammen\n",
    "    min_df=2, # only keep words that appear twice\n",
    "    max_df=0.5 # appears max in 50% of documents\n",
    ")\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(df_selected[\"Consumer complaint narrative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Principal components are chosen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242494, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tSVD = TruncatedSVD(n_components=10)\n",
    "\n",
    "principal_components = tSVD.fit_transform(X_train_counts)\n",
    "print(principal_components.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.26616402 -3.37081231  0.01908446 ...  0.54173743 -1.19513342\n",
      "   0.37070827]\n",
      " [ 3.96354962 -1.099395    0.72606538 ...  0.16371173 -0.62118062\n",
      "  -0.37312326]\n",
      " [14.47191872  7.74605066 -1.50423477 ... -1.66593713  1.42351616\n",
      "   3.06942187]\n",
      " ...\n",
      " [ 0.7278814   0.60665109 -0.70427889 ...  0.1199834  -0.40595955\n",
      "  -0.07083248]\n",
      " [ 5.77501698  4.62779867 -5.63698989 ... -0.84266606 -1.99947676\n",
      "  -0.99502014]\n",
      " [ 6.52529338  1.60217494  0.5335259  ...  2.57380142 -2.09832668\n",
      "   3.37020014]]\n",
      "                0         1         2         3         4         5         6  \\\n",
      "0        4.266164 -3.370812  0.019084  1.007591  0.619244 -0.215616 -0.558814   \n",
      "1        3.963550 -1.099395  0.726065 -0.560019  0.337041  2.802753 -0.221925   \n",
      "2       14.471919  7.746051 -1.504235  1.584361  0.699492 -4.416701 -2.929847   \n",
      "3        2.018344  0.900113  2.367420 -0.566462 -0.510036  1.861475  0.255470   \n",
      "4        4.969348 -4.724663 -1.145122 -3.918889  3.566015  0.821757 -1.412371   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "242489   4.176435 -0.166965  0.600060 -0.477647 -1.719000 -2.796051  1.177344   \n",
      "242490   2.560838  1.935515 -2.688195 -1.541243 -2.620704  0.079894  1.960271   \n",
      "242491   0.727881  0.606651 -0.704279 -0.322144 -0.478184  0.043775  0.217166   \n",
      "242492   5.775017  4.627799 -5.636990 -3.373089 -4.602857  0.341164  3.009982   \n",
      "242493   6.525293  1.602175  0.533526 -1.236356 -0.440134 -4.701208 -1.111486   \n",
      "\n",
      "               7         8         9  \n",
      "0       0.541737 -1.195133  0.370708  \n",
      "1       0.163712 -0.621181 -0.373123  \n",
      "2      -1.665937  1.423516  3.069422  \n",
      "3      -0.478039 -0.475511  0.742832  \n",
      "4       0.574373 -1.672341  0.668825  \n",
      "...          ...       ...       ...  \n",
      "242489  0.148180 -1.438211 -0.710853  \n",
      "242490 -1.068026 -3.162342  0.722201  \n",
      "242491  0.119983 -0.405960 -0.070832  \n",
      "242492 -0.842666 -1.999477 -0.995020  \n",
      "242493  2.573801 -2.098327  3.370200  \n",
      "\n",
      "[242494 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(principal_components)\n",
    "principal_components_df = pd.DataFrame(principal_components)\n",
    "print(principal_components_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One hot encoding of extra columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242494, 10)\n",
      "(242494, 146)\n",
      "(242494, 156)\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding\n",
    "issue_df = pd.Categorical(df_selected['Issue'])\n",
    "\n",
    "df_dummies = pd.get_dummies(issue_df, prefix = 'issue')\n",
    "\n",
    "#X_train_counts_df = pd.DataFrame(X_train_counts)\n",
    "#print(\"DF conversion done\")\n",
    "\n",
    "print(principal_components_df.shape)\n",
    "print(df_dummies.shape)\n",
    "df_concat = pd.concat([principal_components_df, df_dummies], axis = 1)\n",
    "print(df_concat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split into train and test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181870, 156)\n",
      "(60624, 156)\n",
      "(181870,)\n",
      "(60624,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_concat, df_selected['Product'])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Application of linear SVM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l-Larsovic-l\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    precision    recall  f1-score   support\n",
      "\n",
      "                           Bank account or service       1.00      1.00      1.00      3702\n",
      "                       Checking or savings account       0.99      1.00      1.00      4795\n",
      "                                     Consumer Loan       0.95      0.79      0.87      2899\n",
      "                                       Credit card       1.00      1.00      1.00      4667\n",
      "                       Credit card or prepaid card       1.00      0.95      0.97      8268\n",
      "                                  Credit reporting       1.00      1.00      1.00      7884\n",
      "                                   Debt collection       1.00      1.00      1.00      9987\n",
      "Money transfer, virtual currency, or money service       0.99      1.00      0.99      1864\n",
      "                                          Mortgage       0.99      1.00      1.00      7580\n",
      "         Payday loan, title loan, or personal loan       0.73      0.99      0.84      1146\n",
      "                                      Student loan       0.99      0.99      0.99      6249\n",
      "                             Vehicle loan or lease       0.59      0.73      0.66      1583\n",
      "\n",
      "                                          accuracy                           0.97     60624\n",
      "                                         macro avg       0.94      0.95      0.94     60624\n",
      "                                      weighted avg       0.98      0.97      0.98     60624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report # do more stats\n",
    "\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "test_predictions = classifier.predict(X_test)\n",
    "print(classification_report(test_predictions, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
